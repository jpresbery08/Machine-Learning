{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSCI405: Artificial Intelligence\n",
    "## Module 2\n",
    "## Assignment 4: Custom Transformer and Transformation Pipeline\n",
    "\n",
    "#### Name: Jermaine Presbery\n",
    "\n",
    "Begin by writing your name above.\n",
    "\n",
    "Your task in this assignment is to create a custom transformation pipeline that takes in raw data and returns fully prepared, clean data that is ready for model training.  However, we will not actually train any models in this assignment.  This pipeline will employ an imputer class, a user-defined transformer class, and a data-normalization class.\n",
    "\n",
    "Please note that the order of features in the final feature matrix must be correct.  See the below figure that illustrates the input and output of the transformation pipeline.  The positions of features $x_1$ and $x_2$ do not change - they remain in the first and second columns, respectvely, both before and after the transformation pipeline.  In the transformed dataset, the $x_5$ feature is next, and is followed by the newly computed feature $x_6$.  Finally, the last two columns are the remaining one-hot vectors obtained from encoding the categorical feature $x_3$.\n",
    "\n",
    "<img src=\"DataTransformation.png \" width =\"500\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data\n",
    "\n",
    "Import data from the file called `CustomTransformerData.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.354153</td>\n",
       "      <td>COLD</td>\n",
       "      <td>593</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.314048</td>\n",
       "      <td>WARM</td>\n",
       "      <td>340</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.021604</td>\n",
       "      <td>COLD</td>\n",
       "      <td>551</td>\n",
       "      <td>4.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLD</td>\n",
       "      <td>2368</td>\n",
       "      <td>6.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5.5</td>\n",
       "      <td>5.847601</td>\n",
       "      <td>WARM</td>\n",
       "      <td>2636</td>\n",
       "      <td>10.083333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x1        x2    x3    x4         x5\n",
       "0  1.5  2.354153  COLD   593   0.750000\n",
       "1  2.5  3.314048  WARM   340   2.083333\n",
       "2  3.5  4.021604  COLD   551   4.083333\n",
       "3  4.5       NaN  COLD  2368   6.750000\n",
       "4  5.5  5.847601  WARM  2636  10.083333"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# importation of data\n",
    "fileName = \"CustomTransformerData.csv\"\n",
    "df = pd.read_csv(fileName)\n",
    "\n",
    "# Print out first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Custom Transformer\n",
    "\n",
    "Create a custom transformer, just as we did in the lecture video entitled \"Custom Transformers\", that performs two computations: \n",
    "\n",
    "1. Adds an attribute to the end of the data (i.e. new last column) that is equal to $\\frac{x_1^3}{x_5}$ for each observation\n",
    "\n",
    "2. Drops the entire $x_4$ feature column.  (See further instructions below.)\n",
    "\n",
    "You must name your custom transformer class `Assignment4Transformer`.  Your class should include a parameter with a default value of `True` that deletes the $x_4$ feature column when its value is `True`, but preserves the $x_4$ feature column when its value is `False`.\n",
    "\n",
    "NOTE: You must handle the numeric and categorical features separately.  Accordingly, you will not pass the $x_3$ feature column through this custom transformer.  This means your calculations should reflect the absence of the $x_3$ feature column when indexing data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin  #Importation of classes\n",
    "\n",
    "#Creating a class \n",
    "class Assignment4Transformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__ (self, drop_x4 = True, y = None):\n",
    "        self.drop_x4 = drop_x4 \n",
    "    def fit(self, df, y = None):\n",
    "        return self\n",
    "    def transform(self, df, y = None): \n",
    "        new_Col = df[:,0] **3 / df[:,3]\n",
    "        if self.drop_x4:\n",
    "            df = np.delete(df, 2, axis = 1)\n",
    "        return np.c_[df, new_Col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Transformation Pipeline for Numerical Features\n",
    "\n",
    "Create a custom transformation pipeline for numeric data only called `num_pipeline` that:\n",
    "\n",
    "1. Applies the `SimpleImputer` class to the data, where the strategy is set to `mean`.\n",
    "\n",
    "2. Applies the custom `Assignment4Transformer` class to the data.\n",
    "\n",
    "3. Applies the `StandardScaler` class to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importation of classes\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\\\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#Creating a num_pipeline\n",
    "num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy = \"mean\")),\n",
    "            ('attribs_adder', Assignment4Transformer()),\n",
    "            ('std_scaler', StandardScaler())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Numeric and Categorical DataFrames\n",
    "\n",
    "Create two new data frames.  Create one DataFrame called `data_num` that holds the numeric features.  Create another DataFrame called `data_cat` that holds the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Nmeric and Categorical DataFrames\n",
    "data_num = df.drop('x3', axis = 1)\n",
    "data_cat = df.drop(['x1', 'x2', 'x3', 'x4', 'x5'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Testing\n",
    "\n",
    "The full pipeline will be implemented with a `ColumnTransformer` class.  However, to be sure that our numeric pipeline is working properly, lets invoke the `fit_transform()` method of the `num_pipeline` object.  Then, take a look at the transformed data to be sure all is well.\n",
    "\n",
    "### Run Pipeline and Create Transformed Numeric Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Running num_pipeline\n",
    "num_Transformed = num_pipeline.fit_transform(data_num)\n",
    "num_Transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encode Categorical Features\n",
    "\n",
    "Similarly, you will employ a `OneHotEncoder` class in the `ColumnTransformer` below to construct the final full pipeline.  However, let's instantiate an object of the `OneHotEncoder` class called `cat_encoder` that has the `drop` parameter set to `first`.  Next, call the `fit_transform()` method and pass it your categorical data.  Take a look at the transformed one-hot vectors to be sure all is well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], shape=(18, 0), dtype=float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder #Importing onehotencoder\n",
    "cat_encoder = OneHotEncoder(drop = \"first\")   #\n",
    "\n",
    "data_catTransformed = cat_encoder.fit_transform(data_cat) #OneHot encoder presented \n",
    "data_catTransformed.toarray() #Data converted to array "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Put it All Together with a Column Transformer\n",
    "\n",
    "Now, we are finally ready to construct the full transformation pipeline called `full_pipeline` that will transform our raw data into clean, ready-to-train data.  Construct this ColumnTransformer below, then call the `fit_transform()` method to obtain the final, clean data.  Save this output data into a variable called `data_trans`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.63835604, -1.72914963, -1.19507691, -1.59050349,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.44560827, -1.52555901, -1.15738431, -1.39982426,  0.        ,\n",
       "         1.        ],\n",
       "       [-1.2528605 , -1.37548847, -1.10084543, -1.20914502,  0.        ,\n",
       "         0.        ],\n",
       "       [-1.06011273,  0.        , -1.02546024, -1.01846579,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.86736496, -0.9882004 , -0.93122876, -0.82778656,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.67461719, -0.69501705, -0.81815098, -0.63710732,  0.        ,\n",
       "         1.        ],\n",
       "       [-0.48186942, -0.53226557, -0.68622691, -0.44642809,  1.        ,\n",
       "         0.        ],\n",
       "       [-0.28912165, -0.27633017, -0.53545654, -0.25574886,  0.        ,\n",
       "         0.        ],\n",
       "       [-0.09637388, -0.03636359,  0.        , -0.6099295 ,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.09637388,  0.128392  , -0.17737691,  0.12560961,  1.        ,\n",
       "         0.        ],\n",
       "       [ 0.28912165,  0.26571811,  0.02993235,  0.31628884,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.48186942,  0.4501331 ,  0.25608791,  0.50696808,  0.        ,\n",
       "         1.        ],\n",
       "       [ 0.67461719,  0.75841437,  0.50108976,  0.69764731,  0.        ,\n",
       "         0.        ],\n",
       "       [ 0.86736496,  0.88038895,  0.76493791,  0.88832654,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.06011273,  0.        ,  1.04763235,  1.07900578,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.2528605 ,  1.41623801,  1.34917309,  1.26968501,  0.        ,\n",
       "         1.        ],\n",
       "       [ 1.44560827,  1.54702995,  1.66956013,  1.46036424,  1.        ,\n",
       "         0.        ],\n",
       "       [ 1.63835604,  1.71205941,  2.00879346,  1.65104348,  1.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer # Importing ColumnTranformer \n",
    "\n",
    "# ColumnTransformer below\n",
    "full_pipeline = ColumnTransformer([(\"num_transformed\", num_pipeline, [0, 1, 3, 4]),\n",
    "                                    (\"cat_transformed\", cat_encoder, [2])])\n",
    "\n",
    "data_trans = full_pipeline.fit_transform(df)\n",
    "data_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Grading\n",
    "\n",
    "Prepare your `data_trans` NumPy array for grading by using the NumPy [around()](https://numpy.org/doc/stable/reference/generated/numpy.around.html) function to round all the values to 2 decimal places - this will return a NumPy array.\n",
    "\n",
    "Please note the final order of the features in your final numpy array, which is given at the top of this document.\n",
    "\n",
    "___You MUST print your final answer, which is the NumPy array discussed above, using the `print()` function!  This MUST be the only `print()` statement in the entire notebook!  Do not print anything else using the print() function in this notebook!___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.64 -1.73 -1.2  -1.59  0.    0.  ]\n",
      " [-1.45 -1.53 -1.16 -1.4   0.    1.  ]\n",
      " [-1.25 -1.38 -1.1  -1.21  0.    0.  ]\n",
      " [-1.06  0.   -1.03 -1.02  0.    0.  ]\n",
      " [-0.87 -0.99 -0.93 -0.83  0.    1.  ]\n",
      " [-0.67 -0.7  -0.82 -0.64  0.    1.  ]\n",
      " [-0.48 -0.53 -0.69 -0.45  1.    0.  ]\n",
      " [-0.29 -0.28 -0.54 -0.26  0.    0.  ]\n",
      " [-0.1  -0.04  0.   -0.61  0.    1.  ]\n",
      " [ 0.1   0.13 -0.18  0.13  1.    0.  ]\n",
      " [ 0.29  0.27  0.03  0.32  0.    1.  ]\n",
      " [ 0.48  0.45  0.26  0.51  0.    1.  ]\n",
      " [ 0.67  0.76  0.5   0.7   0.    0.  ]\n",
      " [ 0.87  0.88  0.76  0.89  1.    0.  ]\n",
      " [ 1.06  0.    1.05  1.08  1.    0.  ]\n",
      " [ 1.25  1.42  1.35  1.27  0.    1.  ]\n",
      " [ 1.45  1.55  1.67  1.46  1.    0.  ]\n",
      " [ 1.64  1.71  2.01  1.65  1.    0.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(np.around(data_trans,decimals=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
