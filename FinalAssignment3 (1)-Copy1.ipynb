{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q1QjN8HoiEXG"
   },
   "source": [
    "# Assignment 3: Exploring Tree-Based Regression Methods for 3D Sinusoidal Data\n",
    "## DTSC 680: Applied Machine Learning\n",
    "\n",
    "## Name: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-YJTSXjqiEXI"
   },
   "source": [
    "## Directions and Overview\n",
    "\n",
    "The main purpose of this assignment is for you to gain experience using tree-based methods to solve simple regression problems.  In this assignment, you will fit a `Gradient-Boosted Regression Tree`, a `Random Forest`, and a `Decision Tree` to a noisy 3D sinusoidal data set.  Since these models can be trained very quickly on the supplied data, I want you to first manually adjust hyperparameter values and observe their influence on the model's predictions.  That is, you should manually sweep the hyperparameter space and try to hone in on the optimal hyperparameter values, again, _manually_.  (Yep, that means guess-and-check: pick some values, train the model, observe the prediction curve, repeat.)\n",
    "\n",
    "But wait, there's more! Merely attempting to identify the optimal hyperparameter values is not enough.  Be sure to really get a visceral understanding of how altering a hyperparameter in turn alters the model predictions (i.e. the prediction curve).  This is how you will build your machine learning intuition!\n",
    "\n",
    "So, play around and build some models.  When you are done playing with hyperparameter values, you should try to set these values to the optimal values manually (you're likely going to be _way_ off).  Then, retrain the model.  Next in this assignment, we will perform several grid searches, so you'll be able to compare your \"optimal\" hyperparameter values with those computed from the grid search.\n",
    "\n",
    "We will visualize model predictions for the optimal `Gradient-Boosted Regression Tree`, a `Random Forest`, and `Decision Tree` models that were determined by the grid searches.  Next, you will compute the generalization error on the test set for the three models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCZhPZoUiEXJ"
   },
   "source": [
    "## Preliminaries\n",
    "\n",
    "Let's import some common packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "60OT-MDoiEXJ"
   },
   "outputs": [],
   "source": [
    "# Common imports\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "import os\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "FOLDER = \"figures\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, FOLDER)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "    \n",
    "def plot3Ddata(data_df):   \n",
    "    x = data_df['x'].values\n",
    "    y = data_df['y'].values\n",
    "    z = data_df['z'].values\n",
    "    \n",
    "    # Graph Size as a whole \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    \n",
    "    # First subplot - Top Left\n",
    "    ax=fig.add_subplot(2, 2, 1, projection = '3d')\n",
    "    ax.set_xlabel('x', c ='r', size = 16)\n",
    "    ax.set_ylabel('y', c ='r', size = 16)\n",
    "    ax.set_zlabel('z', c ='r', size = 16)\n",
    "    ax.scatter3D(x, y, z, color = \"blue\")\n",
    "    plt.ylim(-6, 6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(0, 90)\n",
    "\n",
    "    # Second subplot - Top Right\n",
    "    ax=fig.add_subplot(2, 2, 2, projection ='3d')\n",
    "\n",
    "    ax.set_xlabel('x',c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x, y, z,  color = 'blue')\n",
    "    plt.ylim(-6, 6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(45, 0)\n",
    "\n",
    "    # Third subplot - Bottom Left\n",
    "    ax=fig.add_subplot(2, 2, 3, projection = '3d')\n",
    "\n",
    "    ax.set_xlabel('x', c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x,y,z,  color ='blue')\n",
    "    plt.ylim(-6,6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(45, 45)\n",
    "\n",
    "    # Fourth subplot - Bottom Right\n",
    "    ax=fig.add_subplot(2, 2, 4, projection='3d')\n",
    "\n",
    "    ax.set_xlabel('x', c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x, y, z,  color = 'blue')\n",
    "    plt.ylim(-6,6)\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "def plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z):\n",
    "\n",
    "    pred =  np.argsort(fit_x)\n",
    "    fit_x = fit_x[pred]\n",
    "    fit_y = fit_y[pred]\n",
    "    fit_z = fit_z[pred]\n",
    "\n",
    "    scat_x = scat_x[pred]\n",
    "    scat_y = scat_y[pred]\n",
    "    scat_z = scat_z[pred]\n",
    "\n",
    "\n",
    "\n",
    "    # Graph Size as a whole \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    \n",
    "    \n",
    "    # First subplot - Top Left\n",
    "    ax=fig.add_subplot(2, 2, 1, projection = '3d')\n",
    "    ax.set_xlabel('x', c ='r', size = 16)\n",
    "    ax.set_ylabel('y', c ='r', size = 16)\n",
    "    ax.set_zlabel('z', c ='r', size = 16)\n",
    "    ax.scatter3D(x, y, z, color = \"blue\")\n",
    "    ax.plot(fit_x, fit_y, fit_z, color = \"black\")\n",
    "    plt.ylim(-6, 6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(0, 90)\n",
    "\n",
    "    # Second subplot - Top Right\n",
    "    ax=fig.add_subplot(2, 2, 2, projection ='3d')\n",
    "\n",
    "    ax.set_xlabel('x',c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x, y, z,  color = 'blue')\n",
    "    ax.plot(fit_x, fit_y, fit_z, color = \"black\")\n",
    "    plt.ylim(-6, 6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(45, 0)\n",
    "\n",
    "    # Third subplot - Bottom Left\n",
    "    ax=fig.add_subplot(2, 2, 3, projection = '3d')\n",
    "\n",
    "    ax.set_xlabel('x', c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x,y,z,  color ='blue')\n",
    "    ax.plot(fit_x, fit_y, fit_z, color = \"black\")\n",
    "    plt.ylim(-6,6)\n",
    "    \n",
    "    # Graph Angle\n",
    "    ax.view_init(45, 45)\n",
    "\n",
    "    # Fourth subplot - Bottom Right\n",
    "    ax =fig.add_subplot(2, 2, 4, projection='3d')\n",
    "\n",
    "    ax.set_xlabel('x', c = 'r', size = 16)\n",
    "    ax.set_ylabel('y', c = 'r', size = 16)\n",
    "    ax.set_zlabel('z', c = 'r', size = 16)\n",
    "    ax.scatter3D(x, y, z,  color = 'blue')\n",
    "    ax.plot(fit_x, fit_y, fit_z, color = \"black\")\n",
    "    plt.ylim(-6,6)\n",
    "\n",
    "    fig.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FvHjcv6iEXK"
   },
   "source": [
    "# Import and Split Data\n",
    "\n",
    "Complete the following:\n",
    "\n",
    "\n",
    "\n",
    "1. Begin by importing the data from the file called `3DSinusoidal.csv`.  Name the returned DataFrame `data`. \n",
    "\n",
    "2. Call [train_test_split()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) with a `test_size` of 20%.  `x` and `y` will be your feature data and `z` will be your response data. Save the output into `X_train`, `X_test`, `z_train`, and `z_test`, respectively.  Specify the `random_state` parameter to be `42` (do this throughout the entire note book)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "wAuGs04siEXK"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'3DSinusoidal.csv' does not exist: b'3DSinusoidal.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-90651ce2935b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Importing data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'3DSinusoidal.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#Creating Feature and Response Data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1135\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1136\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'3DSinusoidal.csv' does not exist: b'3DSinusoidal.csv'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Importing data\n",
    "data=pd.read_csv('3DSinusoidal.csv')\n",
    "\n",
    "#Creating Feature and Response Data\n",
    "X=data[['x','y']]\n",
    "y=data['z']\n",
    "\n",
    "\n",
    "\n",
    "#train_test_split() the X and y\n",
    "X_train,X_test,z_train,z_test=train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Reshapping training and testing data to num\n",
    "X_train = np.array(X_train).reshape(-1,2)\n",
    "X_test = np.array(X_test).reshape(-1,2)\n",
    "z_train = np.array(z_train)\n",
    "z_test = np.array(z_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EoA2C_iYiEXK"
   },
   "source": [
    "# Plot Data\n",
    "\n",
    "Simply plot your training data here, so that you know what you are working with.  You must define a function called `plot3Ddata`, which accepts a Pandas DataFrame (composed of 3 spatial coordinates) and uses `scatter3D()` to plot the data.  Use this function to plot only the training data (recall that you don't even want to look at the test set, until you are ready to calculate the generalization error).  You must place the definition of this function in the existing code cell of the above __Preliminaries__ section, and have nothing other than the function invocation in the below cell. \n",
    "\n",
    "You must emulate the graphs shown in the respective sections below. Each of the graphs will have four subplots. Note the various viewing angles that each subplot presents - you can achieve this with the view_init() method. Be sure to label your axes as shown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "3khvDeF5iEXL",
    "outputId": "02994650-9dff-4efc-e422-15ca5ab889b3"
   },
   "outputs": [],
   "source": [
    "# train_df = pd.DataFrame(X_train)\n",
    "#\n",
    "viz_train_data = np.hstack([X_train, z_train.reshape(-1,1)])\n",
    "train_df = pd.DataFrame(viz_train_data, columns=['x', 'y', 'z'])\n",
    "\n",
    "plot3Ddata(train_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIsxlFu6iEXL"
   },
   "source": [
    "## A Quick Note\n",
    "\n",
    "In the following sections you will be asked to plot the training data along with the model's predictions for that data superimposed on it.  You must write a function called `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` that will plot this figure.  The function accepts six parameters as input, shown in the function signature.  All six input parameters must be NumPy arrays. The Numpy arrays called fit_x and fit_y represent the x and y coordinates from the training data and fit_z represents the model predictions from those coordinates (i.e. the prediction curve). The three Numpy arrays called `scat_x, scat_y,` and  `scat_z` represent the x, y, and z coordinates of the training data.   \n",
    "\n",
    "You must place the definition of the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function in the existing code cell of the above __Preliminaries__ section. (The function header is already there - you must complete the function definition.)\n",
    "\n",
    "You will use the `plotscatter3Ddata()` function in each of the below __Plot Model Predictions for Training Set__ portion of the three __Explore 3D Data__ sections, as well as the __Visualize Optimal Model Predictions__ section.\n",
    "\n",
    "___Important: Below, you will be asked to plot the model's prediction curve along with the training data.  Even if you correctly train the model, you may find that your trendline is very ugly when you first plot it.  If this happens to you, try plotting the model's predictions using a scatter plot rather than a connected line plot.  You should be able to infer the problem and solution with the trendline from examining this new scatter plot of the model's predictions.___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wOvBMmEiEXM"
   },
   "source": [
    "# Explore 3D Data: GradientBoostingRegressor\n",
    "\n",
    "Fit a `GradientBoostingRegressor` model to this data.  You must manually assign values to the following hyperparameters.  You should \"play around\" by using different combinations of hyperparameter values to really get a feel for how they affect the model's predictions.  When you are done playing, set these to the best values you can for submission.  (It is totally fine if you don't elucidate the optimal values here; however, you will want to make sure your model is not excessively overfitting or underfitting the data.  Do this by examining the prediction curve generated by your model.  You will be graded, more exactly, on the values that you calculate later from performing several rounds of grid searches.)\n",
    "\n",
    " - `learning_rate = <value>`\n",
    " - `max_depth = <value>`\n",
    " - `n_estimators = <value>`\n",
    " - `random_state = 42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RNrBsHxBiEXM",
    "outputId": "bd4c9d9e-fd18-46a1-f7ba-2cc89da77c9b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "# X_train=data[:100]\n",
    "#Creating Gradient Boosting Regressor Model\n",
    "gbrt = GradientBoostingRegressor(max_depth=3, n_estimators=42, random_state=42,learning_rate=0.1)\n",
    "gbrt.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "izah7UmEiEXM"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "j63aOTymiEXN",
    "outputId": "15f3861e-8fde-44f6-de3b-4081efa197d8"
   },
   "outputs": [],
   "source": [
    "#Plot Model Predictions\n",
    "\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(gbrt.predict(X_train))\n",
    "\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bhlxl97DiEXN"
   },
   "source": [
    "# Explore 3D Data: RandomForestRegressor\n",
    "\n",
    "Fit a `RandomForestRegressor` model to this data.  You must manually assign values to the following hyperparameters.  You should \"play around\" by using different combinations of hyperparameter values to really get a feel for how they affect the model's predictions.  When you are done playing, set these to the best values you can for submission.  (It is totally fine if you don't elucidate the optimal values here; however, you will want to make sure your model is not excessively overfitting or underfitting the data.  Do this by examining the prediction curve generated by your model.  You will be graded, more exactly, on the values that you calculate later from performing several rounds of grid searches.)\n",
    "\n",
    " - `min_samples_split = <value>`\n",
    " - `max_depth = <value>`\n",
    " - `n_estimators = <value>`\n",
    " - `random_state = 42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kkxeMws6iEXN",
    "outputId": "2b6f456a-5033-45c4-d73d-c3ecf364cfaf"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Creating RandomForestRegressor Model\n",
    "rnd_clf=RandomForestRegressor(n_estimators=50, min_samples_split=0.1,max_depth=8,random_state=42)\n",
    "rnd_clf.fit(X_train,z_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dz1b4bskiEXN"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "FORCS17ziEXO",
    "outputId": "7809fcf7-09b8-4c69-e251-b69fb6fd1adf"
   },
   "outputs": [],
   "source": [
    "#Plotting Model Predictions\n",
    "\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(rnd_clf.predict(X_train))\n",
    "\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)\n",
    "\n",
    "# plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vc2iu-R6iEXO"
   },
   "source": [
    "# Explore 3D Data: DecisionTreeRegressor\n",
    "\n",
    "Fit a `DecisionTreeRegressor` model to this data.  You must manually assign values to the following hyperparameters.  You should \"play around\" by using different combinations of hyperparameter values to really get a feel for how they affect the model's predictions.  When you are done playing, set these to the best values you can for submission.  (It is totally fine if you don't elucidate the optimal values here; however, you will want to make sure your model is not excessively overfitting or underfitting the data.  Do this by examining the prediction curve generated by your model.  You will be graded, more exactly, on the values that you calculate later from performing several rounds of grid searches.)\n",
    " - `splitter = <value>`\n",
    " - `max_depth = <value>`\n",
    " - `min_samples_split = <value>`\n",
    " - `random_state = 42`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gxc_RwP5iEXO",
    "outputId": "58178090-1709-47e1-9f0a-d8d5beeb49ad"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Creating DecisionTreeRegressor Model\n",
    "tree_clf = DecisionTreeRegressor(splitter='best',min_samples_split=5, max_depth=6, random_state=42)\n",
    "tree_clf.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1N1MhihiEXO"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "Qe7Rnr-0iEXO",
    "outputId": "336d88bb-fbf0-4585-d388-44f056b9b0f1"
   },
   "outputs": [],
   "source": [
    "#Plotting Model Predictions for Training Set\n",
    "\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(tree_clf.predict(X_train))\n",
    "\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)\n",
    "# plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LJ1ulFv5iEXP"
   },
   "source": [
    "# Perform Grid Searches\n",
    "\n",
    "You will perform a series of grid searches, which will yield the optimal hyperparamter values for each of the three model types.  You can compare the values computed by the grid search with the values you manually found earlier.  How do these compare?\n",
    "\n",
    "You must perform a course-grained grid search, with a very broad range of values first.  Then, you perform a second grid search using a tighter range of values centered on those identified in the first grid search.  You may have to use another round of grid searching too (it took me at least three rounds of grid searches per model to ascertain the optimal hyperparameter values below).\n",
    "\n",
    "Note the following:\n",
    "\n",
    "1. Be sure to clearly report the optimal hyperparameters in the designated location after you calculate them!\n",
    "\n",
    "2. You must use `random_state=42` everywhere that it is needed in this notebook.\n",
    "\n",
    "3. You must use grid search to compute the following hyperparameters:\n",
    "\n",
    "   GradientBoostingRegressor:\n",
    "    \n",
    "     - `max_depth = <value>`\n",
    "     - `n_estimators = <value>`\n",
    "     - `learning_rate = <value>`\n",
    "\n",
    "   RandomForestRegressor:\n",
    "    \n",
    "     - `max_depth = <value>`\n",
    "     - `n_estimators = <value>`\n",
    "     - `min_samples_split = <value>`\n",
    "\n",
    "   DecisionTreeRegressor:\n",
    "    \n",
    "     - `splitter = <value>`\n",
    "     - `max_depth = <value>`\n",
    "     - `min_samples_split = <value>`\n",
    "     \n",
    "     \n",
    "4. `learning rate` should be rounded to two decimals.\n",
    "5. The number of cross-folds. Specify `cv=3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Unr7R7TiEXP"
   },
   "source": [
    "## Perform Individual Model Grid Searches\n",
    "\n",
    "In this section you will perform a series of grid searches to compute the optimal hyperparameter values for each of the three model types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HYz4eXNciEXP",
    "outputId": "47b72b9d-41ed-4c23-c2ba-c44326b98ab4"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Beginning GradientBoostingRegressor Model\n",
    "param_grid={'max_depth':[1,2,3,4,5,8,16,32],\n",
    "            'n_estimators':[100,200,300,400,500,1000],  \n",
    "            'learning_rate':[.01,.02,.03,.04,.05,.06,.07,1]\n",
    "            }\n",
    "\n",
    "grid_search_cv=GridSearchCV(GradientBoostingRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_cv.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jMvmQYpOgTBW",
    "outputId": "df544db7-ff3c-49e2-9269-abb7246bf4c3"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56-ZGNNLiEXP"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Middle GradientBoostingRegressor Model\n",
    "param_grid={'max_depth':[-20,-10,-5,0,1,2,3,4],\n",
    "            'n_estimators':[-20,-15,-10,-5,0,5,10,25,50,100,200],  \n",
    "            'learning_rate':[.010,.003,.002,.001,.01,.02,.03,.04]\n",
    "            }\n",
    "\n",
    "grid_search_cv=GridSearchCV(GradientBoostingRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_cv.fit(X_train, z_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tIWGwnV_hz9a",
    "outputId": "5b4cd4c8-a8ab-48fb-dab7-d64acf1c511c"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Ap8bhT2iEXQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Final GradientBoostingRegressor Model\n",
    "param_grid={'max_depth':[-20,-10,-5,0,1,2,3,4],\n",
    "            'n_estimators':[-20,-15,-10,-5,0,5,10,25,50,100,200],  \n",
    "            'learning_rate':[.010,.002,.001,.01,.02,.03,.04,.05,.06,.07]\n",
    "            }\n",
    "\n",
    "grid_search_cv=GridSearchCV(GradientBoostingRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_cv.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nMIUY9-JiuhW",
    "outputId": "0e6b2f89-64da-48ed-82d2-ce2b04ea3f44"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hC9Fo2TxiEXQ"
   },
   "source": [
    "On this dataset, the optimal model parameters for the `GradientBoostingRegressor` class are:\n",
    "\n",
    "- `learning_rate = <value>`\n",
    "- `max_depth = <value>`\n",
    "- `n_estimators = <value>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jV8K0NvHiEXQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Initial RandomForestRegressor Model\n",
    "param_grid={'max_depth':[1,2,3,4,5,8,16,32],\n",
    "            'n_estimators':[1,25,50,100,200,400,500,1000],  \n",
    "            'min_samples_split':[1,2,3,4,5,8,10,15,20]\n",
    "            }\n",
    "\n",
    "grid_search_rf=GridSearchCV(RandomForestRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_rf.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mH7Q-NEBjuSb",
    "outputId": "2ea742c5-aa3c-49b9-c43e-20a1957140d5"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rfDyQgdeiEXQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Middle RandomForestRegressor Model\n",
    "param_grid={'max_depth':[-10,-5,3,2,1,2,3,5,10],\n",
    "            'n_estimators':[-10,-7,-6,-5,1,5,6,7,10],  \n",
    "            'min_samples_split':[-10,-6,-5,-2,-1,1,2,3,4]\n",
    "            }\n",
    "\n",
    "grid_search_rf=GridSearchCV(RandomForestRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_rf.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f_XmKaCAmuy8",
    "outputId": "00397874-fbd0-4174-e71c-7c0581f2e6e8"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2iXf5j2uiEXQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Final RandomForestRegressor Model\n",
    "param_grid={'max_depth':[-10,-5,3,2,1,2,3,5,10],\n",
    "            'n_estimators':[-10,-7,-6,-5,1,5,6,7,10],  \n",
    "            'min_samples_split':[-10,-6,-5,-2,-1,1,2,3,4,5,6]\n",
    "            }\n",
    "\n",
    "grid_search_rf=GridSearchCV(RandomForestRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_rf.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1Oscr8Qn6Fw",
    "outputId": "da7818e2-f21e-41bd-e80e-911674e092f0"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNFp4ozAiEXQ"
   },
   "source": [
    "On this dataset, the optimal model parameters for the `RandomForestRegressor` class are:\n",
    "\n",
    "- `max_depth = <value>`\n",
    "- `n_estimators = <value>`\n",
    "- `min_samples_split = <value>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B7b8Bc0PiEXR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Initial DecisionTreeRegressor Model\n",
    "param_grid={'splitter':[\"random\",\"best\"],\n",
    "            'max_depth':[1,2,3,10,15,20,32],  \n",
    "            'min_samples_split':[1,2,3,4,5,8,10,15,20]\n",
    "            }\n",
    "\n",
    "grid_search_dt=GridSearchCV(DecisionTreeRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_dt.fit(X_train, z_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_pKCU3hoMqP",
    "outputId": "9cf3d653-85fa-42ad-838f-54be4d453652"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_dt.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3hknLwkiEXR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "#Final DecisionTree GridSearch\n",
    "param_grid={'splitter':[\"random\"],\n",
    "            'max_depth':[-10,-8,-5,-1,0,1,2,3,10],  \n",
    "            'min_samples_split':[-8,-6,-4,-2,2,3,4,5]\n",
    "            }\n",
    "\n",
    "grid_search_dt=GridSearchCV(DecisionTreeRegressor(random_state=42),param_grid,verbose=1,cv=3)\n",
    "grid_search_dt.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M1eXQpM-oqhR",
    "outputId": "2b3936f3-795c-41b8-fbae-41ff334606a4"
   },
   "outputs": [],
   "source": [
    "print(\"The best parameters are: \", grid_search_dt.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVmiFiWEiEXR"
   },
   "source": [
    "On this dataset, the optimal model parameters for the `RandomForestRegressor` class are:\n",
    "\n",
    "- `splitter = <value>`\n",
    "- `max_depth = <value>`\n",
    "- `min_samples_split = <value>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-vmAWgPiEXR"
   },
   "source": [
    "# Visualize Optimal Model Predictions\n",
    "\n",
    "In the previous section you performed a series of grid searches designed to identify the optimal hyperparameter values for all three models.  Now, use the `best_params_` attribute of the grid search objects from above to create the three optimal models below.  For each model, visualize the models predictions on the training set - this is what we mean by the \"prediction curve\" of the model.\n",
    "\n",
    "### Create Optimal GradientBoostingRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdttNGYMiEXR",
    "outputId": "c1e73f27-e504-41cf-e539-ef491c0ed37b"
   },
   "outputs": [],
   "source": [
    "#Creating GradientBoostingRegressor Model\n",
    "gbrtoptimal = GradientBoostingRegressor(max_depth=3, n_estimators=10, random_state=42,learning_rate=0.07)\n",
    "gbrtoptimal.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k0q96sZ6iEXR"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "xvC7RCzCiEXR",
    "outputId": "0eddd2ea-a1bf-4d8c-d7af-5be1e7d422f2"
   },
   "outputs": [],
   "source": [
    "#Creating Model Predictions\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(gbrtoptimal.predict(X_train))\n",
    "\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "#Plotting Model Predictions\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8vbiwY4iEXS"
   },
   "source": [
    "### Create Optimal RandomForestRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxHofapKiEXS",
    "outputId": "e1c510d7-a963-4546-ccb6-9719d208c83d"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Creating a Random Forest Regressor\n",
    "rnd_clf=RandomForestRegressor(n_estimators=1, min_samples_split=2,max_depth=1,random_state=42)\n",
    "rnd_clf.fit(X_train,z_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYj7I6ryiEXS"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "S09kb9l8iEXS",
    "outputId": "d26314df-2469-4216-b808-dd61bf562212"
   },
   "outputs": [],
   "source": [
    "#Creating Model Predictions for Training Set\n",
    "\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(rnd_clf.predict(X_train))\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2I-WEgX0iEXS"
   },
   "source": [
    "### Create Optimal DecisionTreeRegressor Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3IRZZgniEXS",
    "outputId": "a2274cf4-32c9-44c5-9ac8-4eb9f65d55df"
   },
   "outputs": [],
   "source": [
    "#Creating DecisionTreeRegressor Model\n",
    "\n",
    "\n",
    "tree_clf = DecisionTreeRegressor(splitter='random',min_samples_split=2,max_depth=1, random_state=42)\n",
    "tree_clf.fit(X_train, z_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldO6Xv5niEXS"
   },
   "source": [
    "### Plot Model Predictions for Training Set\n",
    "\n",
    "Use the `plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)` function to plot the data and the prediction curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 730
    },
    "id": "F4nXm5joiEXS",
    "outputId": "2a20b4b0-ce55-407c-b20a-83f2bfa770c4"
   },
   "outputs": [],
   "source": [
    "#Creating Model Predictions\n",
    "\n",
    "fit_x=np.array(train_df['x'])\n",
    "fit_y=np.array(train_df['y'])\n",
    "fit_z=np.array(tree_clf.predict(X_train))\n",
    "\n",
    "scat_x=np.array(train_df['x'])\n",
    "scat_y=np.array(train_df['y'])\n",
    "scat_z=np.array(train_df['z'])\n",
    "\n",
    "\n",
    "plotscatter3Ddata(fit_x, fit_y, fit_z, scat_x, scat_y, scat_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1gch0CELiEXT"
   },
   "source": [
    "# Compute Generalization Error\n",
    "\n",
    "Compute the generalization error for each of the optimal models computed above.  Use MSE as the generalization error metric.  Round your answers to four significant digits.  Print the generalization error for all three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NkxDjtlc2HUh",
    "outputId": "c578b862-42be-4405-d8e6-101ff0717199"
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Z3KulhdiEXT",
    "outputId": "25d523b4-c7bf-408d-ac3f-ee62f314b179"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "models = [gbrtoptimal, rnd_clf, tree_clf]\n",
    "\n",
    "for model in models:\n",
    "    pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(z_test, pred)\n",
    "    print(round(mse, 4))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "FinalAssignment3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
